{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c46e1b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tflite_support.metadata_writers import object_detector\n",
    "from tflite_support.metadata_writers import writer_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0ca037f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"ObjectDetector\",\n",
      "  \"description\": \"Identify which of a known set of objects might be present and provide information about their positions within the given image or a video stream.\",\n",
      "  \"subgraph_metadata\": [\n",
      "    {\n",
      "      \"input_tensor_metadata\": [\n",
      "        {\n",
      "          \"name\": \"image\",\n",
      "          \"description\": \"Input image to be detected.\",\n",
      "          \"content\": {\n",
      "            \"content_properties_type\": \"ImageProperties\",\n",
      "            \"content_properties\": {\n",
      "              \"color_space\": \"RGB\"\n",
      "            }\n",
      "          },\n",
      "          \"process_units\": [\n",
      "            {\n",
      "              \"options_type\": \"NormalizationOptions\",\n",
      "              \"options\": {\n",
      "                \"mean\": [\n",
      "                  127.5\n",
      "                ],\n",
      "                \"std\": [\n",
      "                  127.5\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          ],\n",
      "          \"stats\": {\n",
      "            \"max\": [\n",
      "              1.0\n",
      "            ],\n",
      "            \"min\": [\n",
      "              -1.0\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"output_tensor_metadata\": [\n",
      "        {\n",
      "          \"name\": \"location\",\n",
      "          \"description\": \"The locations of the detected boxes.\",\n",
      "          \"content\": {\n",
      "            \"content_properties_type\": \"BoundingBoxProperties\",\n",
      "            \"content_properties\": {\n",
      "              \"index\": [\n",
      "                1,\n",
      "                0,\n",
      "                3,\n",
      "                2\n",
      "              ],\n",
      "              \"type\": \"BOUNDARIES\"\n",
      "            },\n",
      "            \"range\": {\n",
      "              \"min\": 2,\n",
      "              \"max\": 2\n",
      "            }\n",
      "          },\n",
      "          \"stats\": {\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"output_tensor_groups\": [\n",
      "        {\n",
      "          \"name\": \"detection_result\",\n",
      "          \"tensor_names\": [\n",
      "            \"location\",\n",
      "            \"category\",\n",
      "            \"score\"\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow_lite_support\\metadata\\python\\metadata.py:395: UserWarning: File, 'labels.txt', does not exist in the metadata. But packing it to tflite model is still allowed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ObjectDetectorWriter = object_detector.MetadataWriter\n",
    "_MODEL_PATH = \"best-fp16.tflite\"\n",
    "# Task Library expects label files that are in the same format as the one below.\n",
    "_LABEL_FILE = \"labels.txt\"\n",
    "_SAVE_TO_PATH = \"model_with_metadata.tflite\"\n",
    "# Normalization parameters is required when reprocessing the image. It is\n",
    "# optional if the image pixel values are in range of [0, 255] and the input\n",
    "# tensor is quantized to uint8. See the introduction for normalization and\n",
    "# quantization parameters below for more details.\n",
    "# https://www.tensorflow.org/lite/convert/metadata#normalization_and_quantization_parameters)\n",
    "_INPUT_NORM_MEAN = 127.5\n",
    "_INPUT_NORM_STD = 127.5\n",
    "\n",
    "# Create the metadata writer.\n",
    "writer = ObjectDetectorWriter.create_for_inference(\n",
    "    writer_utils.load_file(_MODEL_PATH), [_INPUT_NORM_MEAN], [_INPUT_NORM_STD],\n",
    "    [_LABEL_FILE])\n",
    "\n",
    "# Verify the metadata generated by metadata writer.\n",
    "print(writer.get_metadata_json())\n",
    "\n",
    "# Populate the metadata into the model.\n",
    "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f3af5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
